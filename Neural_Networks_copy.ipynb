{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xalejandrow/Neural-Networks/blob/main/Neural_Networks_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdJFejbLgiZi"
      },
      "source": [
        "## Recap: Maths in machine learning\n",
        "\n",
        "### 1. Algebra of vectors and matrices\n",
        "\n",
        "#### 1.1 Vectors\n",
        "\n",
        "We have this vector representation:\n",
        "$$ x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} $$\n",
        "\n",
        "The transpose of the two-component column vector is:\n",
        "$$ x^\\mathsf{T}= \\begin{pmatrix} x_1 , x_2 \\end{pmatrix} $$\n",
        "\n",
        "The sum of two column vectors is given by:\n",
        "$$ x+y = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = \\begin{pmatrix} x_1+y_1 \\\\ x_2+y_2 \\end{pmatrix} $$\n",
        "\n",
        "And the inner product by:\n",
        "$$ x^\\mathsf{T}y = \\begin{pmatrix} x_1 , x_2 \\end{pmatrix}  \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = x_1y_1 + x_2y_2 $$\n",
        "\n",
        "The length or euclidean norm of the vector $x$ is:\n",
        "$$ \\Vert x \\Vert = \\sqrt{x_1^2 + x_2^2} = \\sqrt{x^\\mathsf{T}x}$$\n",
        "\n",
        "As we can see, the inner product of $x$ and $y$ can be expressed in terms of the vector lenghts and the angle $\\theta$ between the two vectors:\n",
        "$$ x^\\mathsf{T}y = \\Vert x \\Vert \\Vert y \\Vert \\cos\\theta$$\n",
        "\n",
        "If $\\theta$ is 90 degrees, then the vectors are said to be *orthogonal*, in which case: \n",
        "$$ x^\\mathsf{T}y = 0$$\n",
        "\n",
        "We can see that any vector can be expressed in terms of orthogonal *unit vectors*:\n",
        "$$ x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = x_1 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + x_2 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n",
        "\n",
        "$$ x = x_1i + x_2j$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ty-3HEgiZl"
      },
      "source": [
        "#### 1.2 Matrices\n",
        "\n",
        "A 2x2 matrix is written in the form\n",
        "\n",
        "$$ \\mathbf{A} = \\begin{pmatrix} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{pmatrix} $$\n",
        "\n",
        "The notation per each element in the matrix is: first index means row, second index means column. When a matrix is multiplied with a vector, the result is another vector:\n",
        "\n",
        "$$ \\mathbf{A}x = \\begin{pmatrix} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} a_{11}x_1 + a_{12}x_2 \\\\ a_{21}x_1 + a_{22}x_2 \\end{pmatrix} $$\n",
        "\n",
        "In general, for $ \\mathbf{A} = (a_1, a_2 ... a_N)$, where the vectors $a_i$ are the columns of $\\mathbf{A}$:\n",
        "$$ \\mathbf{A}x = x_1a_1 + x_2a_2 + ... + x_Na_N $$\n",
        "\n",
        "The product of two 2x2 matrices is given by:\n",
        "$$ \\mathbf{A}\\mathbf{B} = \\begin{pmatrix} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{pmatrix} \\begin{pmatrix} b_{11} & b_{12}\\\\ b_{21} & b_{22} \\end{pmatrix} = \\begin{pmatrix} a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\ a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22} \\end{pmatrix}$$\n",
        "\n",
        "The matrix product is allowed whenever $\\mathbf{A}$ has the same number of columns as $\\mathbf{B}$ has rows. So for this case, if $\\mathbf{A}$ has dimension $l$ x $m$ and $\\mathbf{B}$ has dimension $m$ x $n$ then $\\mathbf{A}\\mathbf{B}$ is $l$ x $n$ with elements:\n",
        "$$ (\\mathbf{A}\\mathbf{B})_{ij} = (\\sum_{k=1}^m a_{ik}b_{kj}) : i= 1...l, j= 1...n$$\n",
        "\n",
        "Note that matrix multiplication is not commutative, this means $\\mathbf{A}\\mathbf{B} \\neq \\mathbf{B}\\mathbf{A}$ in general. However it is associative:\n",
        "$$ (\\mathbf{A}\\mathbf{B})\\mathbf{C} = \\mathbf{A}(\\mathbf{B}\\mathbf{C})$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PEGsqMhgiZm",
        "outputId": "3031310b-3419-4c72-ef11-14f65549e37b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Example\n",
        "A = np.array([[1,2],[3,4]])\n",
        "B = np.array([1,1])\n",
        "np.dot(A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py6UdgztgiZn",
        "outputId": "ee78fa45-6dd7-4fec-a182-2cd0f3cbc196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# This is different\n",
        "A * B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp7Cy696giZo",
        "outputId": "0946e100-31f5-485a-e9be-257668f22910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Another way to create a multiplication\n",
        "A @ B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxMZn5c7giZp"
      },
      "source": [
        "![Neural network representation](https://www.datasciencecentral.com/wp-content/uploads/2021/10/2808330901.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2miPK1YgiZq"
      },
      "source": [
        "## 2. Creating a Neural Network\n",
        "\n",
        "Suppose we have the following table:\n",
        "\n",
        "| X1 | X2 | X3 | Y1 |\n",
        "|----|----|----|----|\n",
        "| 0  | 0  | 1  | 0  |\n",
        "| 1  | 1  | 1  | 1  |\n",
        "| 1  | 0  | 1  | 1  |\n",
        "| 0  | 1  | 1  | 0  |\n",
        "\n",
        "As we can see, we have 3 IVs and 1 DV, and by simply using measuring statistics we could see that X1 is perfectly correlated with Y1. Our neural network will have two processes: forward propagation, when creating the inner layers by multiplying the input (IVs) with weights and the backpropagation, when updating the weights.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0,1],\n",
        "              [1,1,1],\n",
        "              [1,0,1],\n",
        "              [0,1,1]])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ-BjOfiVLP",
        "outputId": "64b944ed-2b78-4d94-8160-afae60f9dab5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([[0,1,1,0]])\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cCwnQEPihKy",
        "outputId": "715ad533-b4cc-4f36-856e-307b96b77510"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHVlTNriig-B",
        "outputId": "8ad9fce0-6333-4622-97b1-913c4755c66e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2*np.random.random((3,1)) - 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlUfW1fLju-F",
        "outputId": "4aec6a11-1a10-48eb-c89d-7fa8b37c41ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.71922612],\n",
              "       [-0.60379702],\n",
              "       [ 0.60148914]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVlStpTzgiZq",
        "outputId": "229252bc-167d-4a5a-db44-050295c774a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output After Training:\n",
            "[[0.00966449]\n",
            " [0.99211957]\n",
            " [0.99358898]\n",
            " [0.00786506]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Let's create a sigmoid function (our non linear function)\n",
        "def nonlin(x,deriv=False):\n",
        "    if(deriv==True):\n",
        "        return x*(1-x)\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "# input dataset\n",
        "X = np.array([[0,0,1],\n",
        "              [1,1,1],\n",
        "              [1,0,1],\n",
        "              [0,1,1]])\n",
        "\n",
        "# output dataset           \n",
        "y = np.array([[0,1,1,0]]).T\n",
        "\n",
        "# seed random numbers to make calculation\n",
        "np.random.seed(1)\n",
        "\n",
        "# initialize weights randomly with mean 0\n",
        "syn0 = 2*np.random.random((3,1)) - 1\n",
        " \n",
        "for iter in range(10000):\n",
        "    # forward propagation\n",
        "    l0 = X\n",
        "    l1 = nonlin(np.dot(l0,syn0))\n",
        "    # how much did we miss?\n",
        "    l1_error = y - l1\n",
        "    # multiply how much we missed by the\n",
        "    # slope of the sigmoid at the values in l1\n",
        "    l1_delta = l1_error * nonlin(l1,True)\n",
        "    # update weights\n",
        "    syn0 += np.dot(l0.T,l1_delta)\n",
        "\n",
        "print(\"Output After Training:\")\n",
        "print(l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDlPhnZlgiZs",
        "outputId": "7e60d439-8478-43a7-cfb9-6ef806f3120a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00966449],\n",
              "       [0.99211957],\n",
              "       [0.99358898],\n",
              "       [0.00786506]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Hidden layer\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oBWEsOvgiZt",
        "outputId": "7ed6bc10-948e-43f6-b926-4c9ba7265c5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.67299303],\n",
              "       [-0.2078435 ],\n",
              "       [-4.62963669]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Weights\n",
        "syn0"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.10 ('Commons')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "bc7f7a2d7b5a13e1df9879b693cf35a001b0abe7ad7fabfa2efe5a3b8907473a"
      }
    },
    "colab": {
      "name": "Neural_Networks copy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}